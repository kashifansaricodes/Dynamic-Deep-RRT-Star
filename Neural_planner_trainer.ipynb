{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c385cddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import nltk\n",
    "from PIL import Image\n",
    "import os.path\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import cv2\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from torch.autograd import Variable \n",
    "import math\n",
    "import csv\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c6c246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1.0, 10.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 11.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 12.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 13.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 14.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 15.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 16.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 17.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 18.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 19.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 2.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 3.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 4.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 5.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 6.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 7.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 8.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 9.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0]\n"
     ]
    }
   ],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64 , 128 , 3 , stride = 2 , padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128 , 256 , 3 , stride = 2 , padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256 , 512 , 3 , stride = 2 , padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512 , 1024 , 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(1024 , 2048 , 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(2048 , 28 , 1)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(28, 2048, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(2048, 1024, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(1024, 512, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(512, 256,  3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "    \n",
    "def data_loader(environment_list , N = 200, NP = 201):\n",
    "    \n",
    "    \n",
    "    autoencoder = Autoencoder()\n",
    "    Q = autoencoder.encoder\n",
    "    Q.load_state_dict(torch.load(r\"C:\\Trained_CAE_wights_3\\model_982.pkl\"))\n",
    "    if torch.cuda.is_available():\n",
    "        Q = Q.to(torch.device(\"cuda\"))\n",
    "\n",
    "    encoded_w_m=np.zeros((N,28),dtype=np.float32)\n",
    "    index = 0\n",
    "    for env in environment_list :\n",
    "        env = int(env)\n",
    "#         print('env')\n",
    "#         print(env)\n",
    "#         print(image_number)\n",
    "        image= cv2.imread(f'C:/Deep-RRT-Star-Implementation-main-1/images/{env}.jpg' , cv2.IMREAD_GRAYSCALE)\n",
    "        #cv2.imshow('image' , image)\n",
    "        to_tensor = transforms.ToTensor()\n",
    "        torch_img = to_tensor(image)\n",
    "        if torch.cuda.is_available():\n",
    "            torch_img = torch_img.to(torch.device(\"cuda\"))  # Move input tensor to GPU\n",
    "\n",
    "        output=Q(torch_img)\n",
    "        output = output.squeeze()\n",
    "        output=output.data.cpu()\n",
    "        output = output.numpy()\n",
    "        encoded_w_m[index] = output\n",
    "        index = index + 1\n",
    "    \n",
    "    \n",
    "    file_path = r\"C:\\Users\\Navdeep\\Documents\\output_final.csv\"\n",
    "    dtypes = {col: 'float32' for col in pd.read_csv(file_path, nrows=1).columns}\n",
    "    example = pd.read_csv(file_path, dtype=dtypes)\n",
    "    #print(len(example))\n",
    "    index1 = 0\n",
    "    index2 = 0\n",
    "    index3 = 1\n",
    "    path_lengths=np.zeros((N,NP + 1),dtype=np.float32)\n",
    "    prev_image_number = 0\n",
    "    max_length=0\n",
    "    while index1 < len(example) :\n",
    "        row = example.iloc[index1]\n",
    "        index_start = row['index_start']\n",
    "        index_goal = row['index_goal']\n",
    "        len_path = (index_goal - index_start) + 1\n",
    "        image_number = row['image_number']\n",
    "        index1 = index_goal + 1\n",
    "        index1 = int(index1)\n",
    "#         print('image number')\n",
    "#         print(image_number)\n",
    "        if (image_number == prev_image_number):\n",
    "            path_lengths[index2][0] = image_number\n",
    "            path_lengths[index2][index3] = len_path\n",
    "            index3 = index3 + 1\n",
    "        else :\n",
    "#             print('image number')\n",
    "#             print(prev_image_number)\n",
    "#             print(index3 - 1)\n",
    "            index3 = 1\n",
    "            index2 = index2 + 1\n",
    "            path_lengths[index2][0] = image_number\n",
    "            path_lengths[index2][index3] = len_path\n",
    "            prev_image_number = image_number\n",
    "            index3 = index3 + 1    \n",
    "        if len_path > max_length :\n",
    "            max_length = len_path\n",
    "            \n",
    "    \n",
    "    max_length = int(max_length)\n",
    "    \n",
    "    \n",
    "    path_lengths = path_lengths[:, 1:]\n",
    "    \n",
    "    \n",
    "    \n",
    "    paths=np.zeros((N,NP,max_length,2), dtype=np.float32)\n",
    "    index = 0\n",
    "    index1 = 0\n",
    "    index2 = 0\n",
    "    index3 = 0\n",
    "    prev_image_number = 0\n",
    "    while(index < len(example)) :\n",
    "        row = example.iloc[index]\n",
    "        index_start = int(row['index_start'])\n",
    "        index_goal = int(row['index_goal'])\n",
    "        image_number = row['image_number']  \n",
    "#         print(index_start)\n",
    "        index = index_goal + 1\n",
    "#         print(index_goal)\n",
    "#         print('index2')\n",
    "#         print(index2)\n",
    "        if (image_number == prev_image_number):\n",
    "            index3 = 0\n",
    "            for i in range(index_start , index_goal + 1):\n",
    "                row = example.iloc[i]\n",
    "                # x = row['current_x']\n",
    "                # y = row['current_y']\n",
    "                x = X[i][0]\n",
    "                y = X[i][1]\n",
    "#                 print('x , y')\n",
    "#                 print([x , y])\n",
    "                paths[index1][index2][index3] = [x , y]\n",
    "                #paths[index1][index2][index3][1] = y\n",
    "                index3 = index3 + 1\n",
    "            index2 = index2 + 1  \n",
    "        else :\n",
    "            index1 = index1 + 1\n",
    "            index2 = 0\n",
    "            index3 = 0\n",
    "            \n",
    "            for i in range(index_start , index_goal + 1):\n",
    "                row = example.iloc[i]\n",
    "                # x = row['current_x']\n",
    "                # y = row['current_y']\n",
    "                x = X[i][0]\n",
    "                y = X[i][1]\n",
    "                #print([x , y])\n",
    "                paths[index1][index2][index3] = [x , y]\n",
    "                #paths[index1][index2][index3][1] = y\n",
    "                index3 = index3 + 1\n",
    "            prev_image_number = image_number    \n",
    "            index2 = index2 + 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    dataset=[]\n",
    "    targets=[]\n",
    "    for i in range(N):\n",
    "        for j in range(NP):\n",
    "            if path_lengths[i][j] > 0 :\n",
    "                for m in range(0, int(path_lengths[i][j]-1)):\n",
    "                    data=np.zeros(32,dtype=np.float32)\n",
    "                    for k in range(0 , 28):\n",
    "                        data[k] = encoded_w_m[i][k]\n",
    "                    data[28] = paths[i][j][m][0]\n",
    "                    data[29] = paths[i][j][m][1]\n",
    "                    data[30] = paths[i][j][int(path_lengths[i][j]) - 1][0]\n",
    "                    data[31] = paths[i][j][int(path_lengths[i][j]) - 1][1]\n",
    "                    \n",
    "                    temp = [round(paths[i][j][m+1][0] , 6) , round(paths[i][j][m+1][1] , 6)]\n",
    "                    temp = np.array(temp)\n",
    "                    targets.append(temp)\n",
    "                    dataset.append(data)\n",
    "                    \n",
    "    data = list(zip(dataset, targets))\n",
    "    random.shuffle(data)\n",
    "    dataset,targets=zip(*data)\n",
    "    \n",
    "    return np.asarray(dataset),np.asarray(targets)\n",
    "    \n",
    "    \n",
    "file_path = r\"C:\\Users\\Navdeep\\Documents\\output_final.csv\"\n",
    "dtypes = {col: 'float32' for col in pd.read_csv(file_path, nrows=1).columns}\n",
    "example = pd.read_csv(file_path, dtype=dtypes)\n",
    "index1 = 0\n",
    "index3 = 1\n",
    "prev_image_number = 0\n",
    "environment_list = [0]\n",
    "#print(len(example))\n",
    "while index1 < len(example) :\n",
    "    row = example.iloc[index1]\n",
    "    index_start = row['index_start']\n",
    "    index_goal = row['index_goal']\n",
    "    image_number = row['image_number']\n",
    "    index1 = index_goal + 1\n",
    "    #print(index_goal)\n",
    "    index1 = int(index1)\n",
    "    if (image_number == prev_image_number):\n",
    "        index3 = index3 + 1\n",
    "    else :\n",
    "        environment_list.append(image_number)\n",
    "        index3 = 1\n",
    "        prev_image_number = image_number\n",
    "        index3 = index3 + 1\n",
    "print((environment_list))\n",
    "# with open(file_path, 'r') as file2:\n",
    "#     prev_image_number = 0\n",
    "#     environment_list = [0]\n",
    "#     reader = csv.reader(file2)\n",
    "#     for row in reader:\n",
    "#         if row[-1] == 'image_number':\n",
    "#             continue\n",
    "#         if len(row)==5:\n",
    "#             environment_number =  int(row[-1])\n",
    "#             if environment_number != prev_image_number:\n",
    "#                 environment_list.append(environment_number)\n",
    "#                 prev_image_number = environment_number\n",
    "# print(len(environment_list))\n",
    "\n",
    "dtypes = {col: 'float32' for col in pd.read_csv(file_path, nrows=1).columns}\n",
    "example = pd.read_csv(file_path, dtype=dtypes)\n",
    "sc = StandardScaler()\n",
    "X = example.iloc[:, :2].values\n",
    "X = sc.fit_transform(X)\n",
    "scaler_file = r\"C:\\Users\\Navdeep\\Downloads\\scaler.pkl\"\n",
    "with open(scaler_file, 'wb') as file:\n",
    "    pickle.dump(sc, file)\n",
    "# print(X.shape)\n",
    "# print(len(environment_list))\n",
    "dataset , targets = data_loader(environment_list,200,201)\n",
    "\n",
    "\n",
    "# print(max_length)\n",
    "# print(environment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44be9d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "\t\tnn.Linear(input_size, 1280),nn.PReLU(),nn.Dropout(),\n",
    "\t\tnn.Linear(1280, 1024),nn.PReLU(),nn.Dropout(),\n",
    "\t\tnn.Linear(1024, 896),nn.PReLU(),nn.Dropout(),\n",
    "\t\tnn.Linear(896, 768),nn.PReLU(),nn.Dropout(),\n",
    "\t\tnn.Linear(768, 512),nn.PReLU(),nn.Dropout(),\n",
    "\t\tnn.Linear(512, 384),nn.PReLU(),nn.Dropout(),\n",
    "\t\tnn.Linear(384, 256),nn.PReLU(), nn.Dropout(),\n",
    "\t\tnn.Linear(256, 256),nn.PReLU(), nn.Dropout(),\n",
    "\t\tnn.Linear(256, 128),nn.PReLU(), nn.Dropout(),\n",
    "\t\tnn.Linear(128, 64),nn.PReLU(), nn.Dropout(),\n",
    "\t\tnn.Linear(64, 32),nn.PReLU(),\n",
    "\t\tnn.Linear(32, output_size))\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2240679a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Loss:0.0965\n",
      "Epoch:2, Loss:0.0665\n",
      "Epoch:3, Loss:0.0574\n",
      "Epoch:4, Loss:0.0447\n",
      "Epoch:5, Loss:0.0506\n",
      "Epoch:6, Loss:0.0445\n",
      "Epoch:7, Loss:0.0493\n",
      "Epoch:8, Loss:0.0452\n",
      "Epoch:9, Loss:0.0342\n",
      "Epoch:10, Loss:0.0477\n",
      "Epoch:11, Loss:0.0493\n",
      "Epoch:12, Loss:0.0454\n",
      "Epoch:13, Loss:0.0396\n",
      "Epoch:14, Loss:0.0287\n",
      "Epoch:15, Loss:0.0325\n",
      "Epoch:16, Loss:0.0406\n",
      "Epoch:17, Loss:0.0347\n",
      "Epoch:18, Loss:0.0345\n",
      "Epoch:19, Loss:0.0404\n",
      "Epoch:20, Loss:0.0295\n",
      "Epoch:21, Loss:0.0316\n",
      "Epoch:22, Loss:0.0322\n",
      "Epoch:23, Loss:0.0392\n",
      "Epoch:24, Loss:0.0280\n",
      "Epoch:25, Loss:0.0302\n",
      "Epoch:26, Loss:0.0290\n",
      "Epoch:27, Loss:0.0272\n",
      "Epoch:28, Loss:0.0312\n",
      "Epoch:29, Loss:0.0356\n",
      "Epoch:30, Loss:0.0353\n",
      "Epoch:31, Loss:0.0272\n",
      "Epoch:32, Loss:0.0279\n",
      "Epoch:33, Loss:0.0331\n",
      "Epoch:34, Loss:0.0284\n",
      "Epoch:35, Loss:0.0270\n",
      "Epoch:36, Loss:0.0232\n",
      "Epoch:37, Loss:0.0261\n",
      "Epoch:38, Loss:0.0311\n",
      "Epoch:39, Loss:0.0255\n",
      "Epoch:40, Loss:0.0220\n",
      "Epoch:41, Loss:0.0248\n",
      "Epoch:42, Loss:0.0238\n",
      "Epoch:43, Loss:0.0234\n",
      "Epoch:44, Loss:0.0281\n",
      "Epoch:45, Loss:0.0269\n",
      "Epoch:46, Loss:0.0314\n",
      "Epoch:47, Loss:0.0292\n",
      "Epoch:48, Loss:0.0273\n",
      "Epoch:49, Loss:0.0294\n",
      "Epoch:50, Loss:0.0281\n",
      "Epoch:51, Loss:0.0271\n",
      "Epoch:52, Loss:0.0254\n",
      "Epoch:53, Loss:0.0288\n",
      "Epoch:54, Loss:0.0242\n",
      "Epoch:55, Loss:0.0255\n",
      "Epoch:56, Loss:0.0208\n",
      "Epoch:57, Loss:0.0267\n",
      "Epoch:58, Loss:0.0288\n",
      "Epoch:59, Loss:0.0200\n",
      "Epoch:60, Loss:0.0238\n",
      "Epoch:61, Loss:0.0222\n",
      "Epoch:62, Loss:0.0259\n",
      "Epoch:63, Loss:0.0264\n",
      "Epoch:64, Loss:0.0259\n",
      "Epoch:65, Loss:0.0298\n",
      "Epoch:66, Loss:0.0217\n",
      "Epoch:67, Loss:0.0258\n",
      "Epoch:68, Loss:0.0206\n",
      "Epoch:69, Loss:0.0259\n",
      "Epoch:70, Loss:0.0256\n",
      "Epoch:71, Loss:0.0212\n",
      "Epoch:72, Loss:0.0334\n",
      "Epoch:73, Loss:0.0255\n",
      "Epoch:74, Loss:0.0235\n",
      "Epoch:75, Loss:0.0232\n",
      "Epoch:76, Loss:0.0228\n",
      "Epoch:77, Loss:0.0255\n",
      "Epoch:78, Loss:0.0246\n",
      "Epoch:79, Loss:0.0265\n",
      "Epoch:80, Loss:0.0218\n",
      "Epoch:81, Loss:0.0265\n",
      "Epoch:82, Loss:0.0227\n",
      "Epoch:83, Loss:0.0221\n",
      "Epoch:84, Loss:0.0223\n",
      "Epoch:85, Loss:0.0208\n",
      "Epoch:86, Loss:0.0247\n",
      "Epoch:87, Loss:0.0231\n",
      "Epoch:88, Loss:0.0250\n",
      "Epoch:89, Loss:0.0195\n",
      "Epoch:90, Loss:0.0213\n",
      "Epoch:91, Loss:0.0179\n",
      "Epoch:92, Loss:0.0238\n",
      "Epoch:93, Loss:0.0205\n",
      "Epoch:94, Loss:0.0200\n",
      "Epoch:95, Loss:0.0240\n",
      "Epoch:96, Loss:0.0235\n",
      "Epoch:97, Loss:0.0238\n",
      "Epoch:98, Loss:0.0244\n",
      "Epoch:99, Loss:0.0236\n",
      "Epoch:100, Loss:0.0213\n",
      "Epoch:101, Loss:0.0237\n",
      "Epoch:102, Loss:0.0176\n",
      "Epoch:103, Loss:0.0177\n",
      "Epoch:104, Loss:0.0256\n",
      "Epoch:105, Loss:0.0216\n",
      "Epoch:106, Loss:0.0230\n",
      "Epoch:107, Loss:0.0257\n",
      "Epoch:108, Loss:0.0182\n",
      "Epoch:109, Loss:0.0218\n",
      "Epoch:110, Loss:0.0198\n",
      "Epoch:111, Loss:0.0222\n",
      "Epoch:112, Loss:0.0221\n",
      "Epoch:113, Loss:0.0193\n",
      "Epoch:114, Loss:0.0247\n",
      "Epoch:115, Loss:0.0239\n",
      "Epoch:116, Loss:0.0203\n",
      "Epoch:117, Loss:0.0240\n",
      "Epoch:118, Loss:0.0220\n",
      "Epoch:119, Loss:0.0207\n",
      "Epoch:120, Loss:0.0182\n",
      "Epoch:121, Loss:0.0217\n",
      "Epoch:122, Loss:0.0203\n",
      "Epoch:123, Loss:0.0197\n",
      "Epoch:124, Loss:0.0213\n",
      "Epoch:125, Loss:0.0194\n",
      "Epoch:126, Loss:0.0218\n",
      "Epoch:127, Loss:0.0216\n",
      "Epoch:128, Loss:0.0241\n",
      "Epoch:129, Loss:0.0221\n",
      "Epoch:130, Loss:0.0215\n",
      "Epoch:131, Loss:0.0181\n",
      "Epoch:132, Loss:0.0181\n",
      "Epoch:133, Loss:0.0180\n",
      "Epoch:134, Loss:0.0192\n",
      "Epoch:135, Loss:0.0220\n",
      "Epoch:136, Loss:0.0205\n",
      "Epoch:137, Loss:0.0214\n",
      "Epoch:138, Loss:0.0229\n",
      "Epoch:139, Loss:0.0199\n",
      "Epoch:140, Loss:0.0214\n",
      "Epoch:141, Loss:0.0230\n",
      "Epoch:142, Loss:0.0198\n",
      "Epoch:143, Loss:0.0236\n",
      "Epoch:144, Loss:0.0207\n",
      "Epoch:145, Loss:0.0181\n",
      "Epoch:146, Loss:0.0236\n",
      "Epoch:147, Loss:0.0207\n",
      "Epoch:148, Loss:0.0203\n",
      "Epoch:149, Loss:0.0238\n",
      "Epoch:150, Loss:0.0235\n",
      "Epoch:151, Loss:0.0196\n",
      "Epoch:152, Loss:0.0222\n",
      "Epoch:153, Loss:0.0207\n",
      "Epoch:154, Loss:0.0206\n",
      "Epoch:155, Loss:0.0188\n",
      "Epoch:156, Loss:0.0227\n",
      "Epoch:157, Loss:0.0227\n",
      "Epoch:158, Loss:0.0229\n",
      "Epoch:159, Loss:0.0201\n",
      "Epoch:160, Loss:0.0198\n",
      "Epoch:161, Loss:0.0211\n",
      "Epoch:162, Loss:0.0208\n",
      "Epoch:163, Loss:0.0225\n",
      "Epoch:164, Loss:0.0192\n",
      "Epoch:165, Loss:0.0206\n",
      "Epoch:166, Loss:0.0227\n",
      "Epoch:167, Loss:0.0178\n",
      "Epoch:168, Loss:0.0198\n",
      "Epoch:169, Loss:0.0198\n",
      "Epoch:170, Loss:0.0150\n",
      "Epoch:171, Loss:0.0206\n",
      "Epoch:172, Loss:0.0207\n",
      "Epoch:173, Loss:0.0196\n",
      "Epoch:174, Loss:0.0190\n",
      "Epoch:175, Loss:0.0185\n",
      "Epoch:176, Loss:0.0171\n",
      "Epoch:177, Loss:0.0205\n",
      "Epoch:178, Loss:0.0302\n",
      "Epoch:179, Loss:0.0197\n",
      "Epoch:180, Loss:0.0208\n",
      "Epoch:181, Loss:0.0201\n",
      "Epoch:182, Loss:0.0236\n",
      "Epoch:183, Loss:0.0194\n",
      "Epoch:184, Loss:0.0189\n",
      "Epoch:185, Loss:0.0190\n",
      "Epoch:186, Loss:0.0191\n",
      "Epoch:187, Loss:0.0205\n",
      "Epoch:188, Loss:0.0174\n",
      "Epoch:189, Loss:0.0214\n",
      "Epoch:190, Loss:0.0200\n",
      "Epoch:191, Loss:0.0187\n",
      "Epoch:192, Loss:0.0207\n",
      "Epoch:193, Loss:0.0180\n",
      "Epoch:194, Loss:0.0200\n",
      "Epoch:195, Loss:0.0187\n",
      "Epoch:196, Loss:0.0244\n",
      "Epoch:197, Loss:0.0182\n",
      "Epoch:198, Loss:0.0187\n",
      "Epoch:199, Loss:0.0179\n",
      "Epoch:200, Loss:0.0172\n",
      "Epoch:201, Loss:0.0160\n",
      "Epoch:202, Loss:0.0218\n",
      "Epoch:203, Loss:0.0188\n",
      "Epoch:204, Loss:0.0201\n",
      "Epoch:205, Loss:0.0243\n",
      "Epoch:206, Loss:0.0216\n",
      "Epoch:207, Loss:0.0194\n",
      "Epoch:208, Loss:0.0203\n",
      "Epoch:209, Loss:0.0190\n",
      "Epoch:210, Loss:0.0230\n",
      "Epoch:211, Loss:0.0202\n",
      "Epoch:212, Loss:0.0214\n",
      "Epoch:213, Loss:0.0208\n",
      "Epoch:214, Loss:0.0181\n",
      "Epoch:215, Loss:0.0209\n",
      "Epoch:216, Loss:0.0180\n",
      "Epoch:217, Loss:0.0183\n",
      "Epoch:218, Loss:0.0186\n",
      "Epoch:219, Loss:0.0209\n",
      "Epoch:220, Loss:0.0211\n",
      "Epoch:221, Loss:0.0194\n",
      "Epoch:222, Loss:0.0179\n",
      "Epoch:223, Loss:0.0198\n",
      "Epoch:224, Loss:0.0208\n",
      "Epoch:225, Loss:0.0207\n",
      "Epoch:226, Loss:0.0193\n",
      "Epoch:227, Loss:0.0186\n",
      "Epoch:228, Loss:0.0192\n",
      "Epoch:229, Loss:0.0195\n",
      "Epoch:230, Loss:0.0144\n",
      "Epoch:231, Loss:0.0212\n",
      "Epoch:232, Loss:0.0165\n",
      "Epoch:233, Loss:0.0175\n",
      "Epoch:234, Loss:0.0223\n",
      "Epoch:235, Loss:0.0184\n",
      "Epoch:236, Loss:0.0236\n",
      "Epoch:237, Loss:0.0188\n",
      "Epoch:238, Loss:0.0221\n",
      "Epoch:239, Loss:0.0189\n",
      "Epoch:240, Loss:0.0189\n",
      "Epoch:241, Loss:0.0179\n",
      "Epoch:242, Loss:0.0158\n",
      "Epoch:243, Loss:0.0199\n",
      "Epoch:244, Loss:0.0200\n",
      "Epoch:245, Loss:0.0199\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(bo,bt)\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m#avg_loss=avg_loss+loss.data[0]\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     40\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     41\u001b[0m model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(epoch)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     tensors,\n\u001b[0;32m    253\u001b[0m     grad_tensors_,\n\u001b[0;32m    254\u001b[0m     retain_graph,\n\u001b[0;32m    255\u001b[0m     create_graph,\n\u001b[0;32m    256\u001b[0m     inputs,\n\u001b[0;32m    257\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    258\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    259\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def to_var(x, volatile=False):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.to(torch.device(\"cuda\"))\n",
    "    return x\n",
    "\n",
    "def get_input(i,data,targets,bs):\n",
    "    if i+bs<len(data):\n",
    "        bi=data[i:i+bs]\n",
    "        bt=targets[i:i+bs]\n",
    "    else:\n",
    "        bi=data[i:]\n",
    "        bt=targets[i:]\n",
    "    return torch.from_numpy(bi),torch.from_numpy(bt)\n",
    "\n",
    "#dataset,targets= load_dataset()\n",
    "#I have to yet write the architecture for the model\n",
    "mlp = MLP(32, 2)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    mlp = mlp.to(torch.device(\"cuda\"))\n",
    "    \n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adagrad(mlp.parameters())\n",
    "\n",
    "total_loss=[]\n",
    "sm=100 \n",
    "#training the model for 1000 epochs\n",
    "for epoch in range(1000):\n",
    "    #print (\"epoch\" + str(epoch))\n",
    "    avg_loss=0\n",
    "    for i in range (0,len(dataset),100):\n",
    "        mlp.zero_grad()\n",
    "        bi,bt= get_input(i,dataset,targets,100)\n",
    "        bi=to_var(bi)\n",
    "        bt=to_var(bt)\n",
    "        bo = mlp(bi)\n",
    "        loss = criterion(bo,bt)\n",
    "        #avg_loss=avg_loss+loss.data[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model_path='model_'+str(epoch)+'.pkl'\n",
    "    save_path = r\"C:\\Trained_planner_weights_4\"\n",
    "    path = os.path.join(save_path , model_path)\n",
    "    torch.save(mlp.state_dict(),path)\n",
    "    print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}')  \n",
    "#     print \"--average loss:\"\n",
    "#     print avg_loss/(len(dataset)/args.batch_size)\n",
    "    total_loss.append(avg_loss/(len(dataset)/100))\n",
    "    # Save the models\n",
    "#     if epoch==sm:\n",
    "#         model_path='model'+str(sm)+'.pkl'\n",
    "#         save_path = '/home/sj/Deep-RRT-Star-Implementation/weights/model_weights'\n",
    "#         torch.save(mlp.state_dict(),os.path.join(save_path , model_path))\n",
    "#         sm=sm+50 # save model after every 50 epochs from 100 epoch ownwards\n",
    "\n",
    "            \n",
    "#Following are the commands for saving the final model.            \n",
    "# model_path=r'C:\\Deep-RRT-Star-Implementation-main\\final_model\\final_model.pkl'\n",
    "# torch.save(mlp.state_dict() , model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bad3870e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Trained_planner_weights\\model_10.pkl\n"
     ]
    }
   ],
   "source": [
    "model_path='model_'+str(epoch)+'.pkl'\n",
    "save_path = r\"C:\\Trained_planner_weights\"\n",
    "path = os.path.join(save_path , model_path)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f69e389b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m#print(index_start)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     index1 \u001b[38;5;241m=\u001b[39m index_goal \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 20\u001b[0m     index1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (image_number \u001b[38;5;241m!=\u001b[39m prev_image_number):\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#         path_lengths[index2][0] = image_number\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#         path_lengths[index2][index3] = len_path\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#         index3 = index3 + 1\u001b[39;00m\n\u001b[1;32m     25\u001b[0m           \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage number\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "file_path = r\"/home/sj/Deep-RRT-Star-Implementation/output.csv\"\n",
    "# dtypes = {col: 'float32' for col in pd.read_csv(file_path, nrows=1).columns}\n",
    "example = pd.read_csv(file_path, dtype=dtypes)\n",
    "#print(len(example))\n",
    "index1 = 0\n",
    "# index2 = 0\n",
    "# index3 = 1\n",
    "# path_lengths=np.zeros((N,NP + 1),dtype=np.float32)\n",
    "prev_image_number = 0\n",
    "# max_length=0\n",
    "number_of_environments = 0\n",
    "while index1 < len(example) :\n",
    "    row = example.iloc[index1]\n",
    "    index_start = row['index_start']\n",
    "    index_goal = row['index_goal']\n",
    "#     len_path = (index_goal - index_start) + 1\n",
    "    image_number = row['image_number']\n",
    "    #print(index_start)\n",
    "    index1 = index_goal + 1\n",
    "    index1 = int(index1)\n",
    "    if (image_number != prev_image_number):\n",
    "#         path_lengths[index2][0] = image_number\n",
    "#         path_lengths[index2][index3] = len_path\n",
    "#         index3 = index3 + 1\n",
    "          print('image number')\n",
    "          print(prev_image_number)\n",
    "          print(index3 - 1)\n",
    "          prev_image_number = image_number\n",
    "#           number_of_environments = number_of_environments + 1\n",
    "#         index3 = 1\n",
    "#         index2 = index2 + 1\n",
    "#         path_lengths[index2][0] = image_number\n",
    "#         path_lengths[index2][index3] = len_path\n",
    "#         prev_image_number = image_number\n",
    "#         index3 = index3 + 1    \n",
    "#     if len_path > max_length :\n",
    "#         max_length = len_path\n",
    "\n",
    "print(number_of_environments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9979f7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 , 35.0\n",
      "36.0 , 62.0\n",
      "63.0 , 101.0\n",
      "102.0 , 113.0\n",
      "114.0 , 134.0\n",
      "135.0 , 141.0\n",
      "143.0 , 162.0\n",
      "nan , nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(index_start, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_goal)\n\u001b[1;32m     19\u001b[0m     index1 \u001b[38;5;241m=\u001b[39m index_goal \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 20\u001b[0m     index1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (image_number \u001b[38;5;241m==\u001b[39m prev_image_number):\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#             path_lengths[index2][0] = image_number\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#             path_lengths[index2][index3] = len_path\u001b[39;00m\n\u001b[1;32m     24\u001b[0m         index3 \u001b[38;5;241m=\u001b[39m index3 \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "file_path = r\"/home/sj/Deep-RRT-Star-Implementation/output.csv\"\n",
    "dtypes = {col: 'float32' for col in pd.read_csv(file_path, nrows=1).columns}\n",
    "example = pd.read_csv(file_path, dtype=dtypes)\n",
    "#print(len(example))\n",
    "index1 = 0\n",
    "#     index2 = 0\n",
    "index3 = 1\n",
    "#     path_lengths=np.zeros((N,NP + 1),dtype=np.float32)\n",
    "prev_image_number = 0\n",
    "#     max_length=0\n",
    "environment_list = [0]\n",
    "while index1 < len(example) :\n",
    "    row = example.iloc[index1]\n",
    "    index_start = row['index_start']\n",
    "    index_goal = row['index_goal']\n",
    "    len_path = (index_goal - index_start) + 1\n",
    "    image_number = row['image_number']\n",
    "    print(index_start, \",\", index_goal)\n",
    "    index1 = index_goal + 1\n",
    "    index1 = int(index1)\n",
    "    if (image_number == prev_image_number):\n",
    "#             path_lengths[index2][0] = image_number\n",
    "#             path_lengths[index2][index3] = len_path\n",
    "        index3 = index3 + 1\n",
    "    else :\n",
    "#         print('image number')\n",
    "#         print(prev_image_number)\n",
    "        environment_list.append(image_number)\n",
    "#         print(index3 - 1)\n",
    "        index3 = 1\n",
    "#             index2 = index2 + 1\n",
    "#             path_lengths[index2][0] = image_number\n",
    "#             path_lengths[index2][index3] = len_path\n",
    "        prev_image_number = image_number\n",
    "        index3 = index3 + 1    \n",
    "#         if len_path > max_length :\n",
    "#             max_length = len_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "893bbe01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "print(len(environment_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebd82458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "directory = r\"C:\\Users\\Navdeep\\Downloads\\images\\images\"\n",
    "for env in environment_list :\n",
    "    env = np.float32(env)\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".JPG\"):\n",
    "            numeric_part = os.path.splitext(filename)[0]\n",
    "            numeric_value = np.float32(numeric_part)\n",
    "            if (numeric_value == env):\n",
    "                image_path = os.path.join(directory, filename)\n",
    "                image = cv2.imread(image_path)\n",
    "                output_directory = r'C:\\images_modified'\n",
    "                output_path = os.path.join(output_directory, filename)\n",
    "                cv2.imwrite(output_path, image)\n",
    "            \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28eabbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "directory = 'C:\\images_modified'\n",
    "files = os.listdir(directory)\n",
    "num_files = len(files)\n",
    "print(num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9b918c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317938\n"
     ]
    }
   ],
   "source": [
    "file_path = r\"C:\\Users\\Navdeep\\Downloads\\output.csv\"\n",
    "dtypes = {col: 'float32' for col in pd.read_csv(file_path, nrows=1).columns}\n",
    "example = pd.read_csv(file_path, dtype=dtypes)\n",
    "\n",
    "print(len(example))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
